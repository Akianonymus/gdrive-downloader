#!/usr/bin/env bash
SELF_SOURCE="true"
_bytes_to_human(){
declare b="${1:-0}" d='' s=0 S=(Bytes {K,M,G,T,P,E,Y,Z}B)
b="$(printf "%.0f\n" "$b")"
while ((b>1024));do
d="$(printf ".%02d" $((b%1024*100/1024)))"
b=$((b/1024))&&((s++))
done
printf "%s\n" "$b$d ${S[$s]}"
}
_check_bash_version(){
{ ! [[ ${BASH_VERSINFO:-0} -ge 4 ]]&&printf "Bash version lower than 4.x not supported.\n"&&exit 1;}||:
}
_check_debug(){
_print_center_quiet(){ { [[ $# == 3 ]]&&printf "%s\n" "$2";}||{ printf "%s%s\n" "$2" "$3";};}
if [[ -n $DEBUG ]];then
set -x&&PS4='-> '
_print_center(){ { [[ $# == 3 ]]&&printf "%s\n" "$2";}||{ printf "%s%s\n" "$2" "$3";};}
_clear_line(){ :;}&&_newline(){ :;}
else
if [[ -z $QUIET ]];then
if [[ -t 2 && -n $TERM && $TERM =~ (xterm|rxvt|urxvt|linux|vt) ]];then
shopt -s checkwinsize&&(:&&:)
if [[ $COLUMNS -lt 45 ]];then
_print_center(){ { [[ $# == 3 ]]&&printf "%s\n" "[ $2 ]";}||{ printf "%s\n" "[ $2$3 ]";};}
else
trap 'shopt -s checkwinsize; (:;:)' SIGWINCH
fi
EXTRA_LOG="_print_center" CURL_PROGRESS="-#"&&export CURL_PROGRESS EXTRA_LOG
else
_print_center(){ { [[ $# == 3 ]]&&printf "%s\n" "[ $2 ]";}||{ printf "%s\n" "[ $2$3 ]";};}
_clear_line(){ :;}
fi
_newline(){ printf "%b" "$1";}
else
_print_center(){ :;}&&_clear_line(){ :;}&&_newline(){ :;}
fi
set +x
fi
}
_check_internet(){
"$EXTRA_LOG" "justify" "Checking Internet Connection.." "-"
if ! _timeout 10 curl -Is google.com;then
_clear_line 1
"${QUIET:-_print_center}" "justify" "Error: Internet connection" " not available." "="
exit 1
fi
_clear_line 1
}
_clear_line(){
printf "\033[%sA\033[2K" "$1"
}
_count(){
mapfile -tn 0 lines
printf '%s\n' "${#lines[@]}"
}
_json_value(){
declare num _tmp no_of_lines
{ [[ $2 -gt 0 ]]&&no_of_lines="$2";}||:
{ [[ $3 -gt 0 ]]&&num="$3";}||{ [[ $3 != all ]]&&num=1;}
_tmp="$(grep -o "\"$1\"\:.*" ${no_of_lines:+-m} $no_of_lines)"||return 1
printf "%s\n" "$_tmp"|sed -e 's/.*"'"$1""\"://" -e 's/[",]*$//' -e 's/["]*$//' -e 's/[,]*$//' -e "s/^ //" -e 's/^"//' -n -e "$num"p||:
}
_print_center(){
[[ $# -lt 3 ]]&&printf "%s: Missing arguments\n" "${FUNCNAME[0]}"&&return 1
declare -i TERM_COLS="$COLUMNS"
declare type="$1" filler
case "$type" in
normal)declare out="$2"&&symbol="$3";;
justify)if
[[ $# == 3 ]]
then
declare input1="$2" symbol="$3" TO_PRINT out
TO_PRINT="$((TERM_COLS-5))"
{ [[ ${#input1} -gt $TO_PRINT ]]&&out="[ ${input1:0:TO_PRINT}..]";}||{ out="[ $input1 ]";}
else
declare input1="$2" input2="$3" symbol="$4" TO_PRINT temp out
TO_PRINT="$((TERM_COLS*47/100))"
{ [[ ${#input1} -gt $TO_PRINT ]]&&temp+=" ${input1:0:TO_PRINT}..";}||{ temp+=" $input1";}
TO_PRINT="$((TERM_COLS*46/100))"
{ [[ ${#input2} -gt $TO_PRINT ]]&&temp+="${input2:0:TO_PRINT}.. ";}||{ temp+="$input2 ";}
out="[$temp]"
fi
;;
*)return 1
esac
declare -i str_len=${#out}
[[ $str_len -ge $((TERM_COLS-1)) ]]&&{
printf "%s\n" "$out"&&return 0
}
declare -i filler_len="$(((TERM_COLS-str_len)/2))"
[[ $# -ge 2 ]]&&ch="${symbol:0:1}"||ch=" "
for ((i=0; i<filler_len; i++));do
filler="$filler$ch"
done
printf "%s%s%s" "$filler" "$out" "$filler"
[[ $(((TERM_COLS-str_len)%2)) -ne 0 ]]&&printf "%s" "$ch"
printf "\n"
return 0
}
_timeout(){
declare timeout="${1:?Error: Specify Timeout}"&&shift
{
"$@"&
child="$!"
trap -- "" TERM
{
sleep "$timeout"
kill "$child"
}&
wait "$child"
} 2>|/dev/null 1>&2
}
_update_config(){
[[ $# -lt 3 ]]&&printf "Missing arguments\n"&&return 1
declare value_name="$1" value="$2" config_path="$3"
! [ -f "$config_path" ]&&: >|"$config_path"
chmod u+w "$config_path"
printf "%s\n%s\n" "$(grep -v -e "^$" -e "^$value_name=" "$config_path"||:)" \
"$value_name=\"$value\"" >|"$config_path"
chmod u-w+r "$config_path"
}
_download_file(){
[[ $# -lt 3 ]]&&printf "%s: Missing arguments\n" "${FUNCNAME[0]}"&&return 1
declare file_id="$1" name="$2" server_size="$3" parallel="$4"
declare range status old_status left downloaded
server_size_readable="$(_bytes_to_human "$server_size")"
_print_center "justify" "$name" " | ${server_size:+$server_size_readable}" "="
if [[ -s $name ]];then
declare local_size&&local_size="$(wc -c <"$name")"
if [[ $local_size -ge $server_size ]];then
"${QUIET:-_print_center}" "justify" "File already present" "="&&_newline "\n"
_log_in_file
return 0
else
_print_center "justify" "File is partially" " present, resuming.." "-"
range="Range: bytes=$local_size-$server_size"
fi
else
range="Range: bytes=0-$server_size"
_print_center "justify" "Downloading file.." "-"
fi
if [[ -n $OAUTH_ENABLED ]];then
. "${TMPFILE}_ACCESS_TOKEN"
curl -Ls $CURL_SPEED \
-H "$range" \
-H "Authorization: Bearer $ACCESS_TOKEN" \
"$API_URL/drive/$API_VERSION/files/$file_id?alt=media&supportsAllDrives=true&includeItemsFromAllDrives=true" >>"$name"&
pid="$!"
elif [[ -n $API_KEY_DOWNLOAD ]];then
curl -Ls $CURL_SPEED \
-H "$range" \
-e "https://drive.google.com" \
"$API_URL/drive/$API_VERSION/files/$file_id?alt=media&supportsAllDrives=true&includeItemsFromAllDrives=true&key=$API_KEY" >>"$name"&
pid="$!"
else
"$EXTRA_LOG" "justify" "Fetching" " cookies.." "-"
curl -c "$TMPFILE"COOKIE -I $CURL_PROGRESS -o /dev/null "https://drive.google.com/uc?export=download&id=$file_id"||:
for _ in 1 2;do _clear_line 1;done
confirm_string="$(: "$(grep -F 'download_warning' "$TMPFILE"COOKIE)"&&printf "%s\n" "${_//*$'\t'/}")"||:
curl -Ls $CURL_SPEED \
-H "$range" \
-b "$TMPFILE"COOKIE \
"https://drive.google.com/uc?export=download&id=$file_id${confirm_string:+&confirm=$confirm_string}" >>"$name"&
pid="$!"
fi
if [[ -n $parallel ]];then
wait "$pid" 2>|/dev/null 1>&2
else
until [[ -f $name ]];do sleep 0.5;done
until ! kill -0 "$pid" 2>|/dev/null 1>&2;do
downloaded="$(wc -c <"$name")"
status="$(_bytes_to_human "$downloaded")"
left="$(_bytes_to_human "$((server_size-downloaded))")"
sleep 0.5
if [[ $status != "$old_status" ]];then
printf '%s\r' "$(_print_center "justify" "Downloaded: $status" " | Left: $left" "=")"
fi
old_status="$status"
done
_newline "\n"
fi
if [[ $(wc -c <"$name") -ge $server_size ]];then
for _ in 1 2;do _clear_line 1;done
"${QUIET:-_print_center}" "justify" "Downloaded" "="&&_newline "\n"
else
"${QUIET:-_print_center}" "justify" "Error: Incomplete" " download." "=" 1>&2
return 1
fi
_log_in_file "$name" "$server_size_readable" "$file_id"
return 0
}
_download_file_main(){
[[ $# -lt 2 ]]&&printf "%s: Missing arguments\n" "${FUNCNAME[0]}" 1>&2&&return 1
declare line fileid name size parallel retry="${RETRY:-0}"&&unset RETURN_STATUS
[[ $1 == parse ]]&&parallel="$3" line="$2" fileid="${line%%"|:_//_:|"*}" \
name="${line##*"|:_//_:|"}" size="$(_tmp="${line#*"|:_//_:|"}"&&printf "%s\n" "${_tmp%"|:_//_:|"*}")"
parallel="${parallel:-$5}"
unset RETURN_STATUS&&until [[ $retry -le 0 && -n $RETURN_STATUS ]];do
if [[ -n $parallel ]];then
_download_file "${fileid:-$2}" "${name:-$3}" "${size:-$4}" true 2>|/dev/null 1>&2&&RETURN_STATUS=1&&break
else
_download_file "${fileid:-$2}" "${name:-$3}" "${size:-$4}"&&RETURN_STATUS=1&&break
fi
RETURN_STATUS=2 retry="$((retry-1))"&&continue
done
{ [[ $RETURN_STATUS == 1 ]]&&printf "%b" "${parallel:+$RETURN_STATUS\n}";}||printf "%b" "${parallel:+$RETURN_STATUS\n}" 1>&2
return 0
}
_download_folder(){
[[ $# -lt 2 ]]&&printf "%s: Missing arguments\n" "${FUNCNAME[0]}"&&return 1
declare folder_id="$1" name="$2" parallel="$3"
declare json_search json_search_fragment next_page_token \
error_status success_status files=() folders=() \
files_size files_name files_list num_of_files folders_list num_of_folders
_newline "\n"
"$EXTRA_LOG" "justify" "$name" "="
"$EXTRA_LOG" "justify" "Fetching folder" " details.." "-"
_search_error_message(){
"${QUIET:-_print_center}" "justify" "Error: Cannot" ", fetch folder details." "="
printf "%s\n" "${1:?}"&&return 1
}
if json_search="$("$API_REQUEST_FUNCTION" "files?q=%27$folder_id%27+in+parents&fields=nextPageToken,files(name,size,id,mimeType)&pageSize=1000")";then
until ! next_page_token="$(_json_value nextPageToken 1 1 <<<"${json_search_fragment:-$json_search}")";do
json_search_fragment="$("$API_REQUEST_FUNCTION" "files?q=%27$folder_id%27+in+parents&fields=nextPageToken,files(name,size,id,mimeType)&pageSize=1000&pageToken=$next_page_token")"||_search_error_message "$json_search_fragment"
json_search="$json_search
$json_search_fragment"
done
else
_search_error_message "$json_search"
fi&&_clear_line 1
"$EXTRA_LOG" "justify" "Preparing files list.." "="
mapfile -t files <<<"$(printf "%s\n" "$json_search"|grep '"size":' -B3|_json_value id all all)"||:
files_size="$(_json_value size all all <<<"$json_search")"||:
files_name="$(printf "%s\n" "$json_search"|grep size -B2|_json_value name all all)"||:
files_list="$(while read -r -u 4 _id&&read -r -u 5 _size&&read -r -u 6 _name;do
printf "%s\n" "$_id|:_//_:|$_size|:_//_:|$_name"
done 4<<<"$(printf "%s\n" "${files[@]}")" 5<<<"$files_size" 6<<<"$files_name")"
_clear_line 1
"$EXTRA_LOG" "justify" "Preparing sub folders list.." "="
mapfile -t folders <<<"$(printf "%s\n" "$json_search"|grep '"mimeType":.*folder.*' -B2|_json_value id all all)"||:
folders_name="$(printf "%s\n" "$json_search"|grep '"mimeType":.*folder.*' -B1|_json_value name all all)"||:
folders_list="$(while read -r -u 4 _id&&read -r -u 5 _name;do
printf "%s\n" "$_id|:_//_:|$_name"
done 4<<<"$(printf "%s\n" "${folders[@]}")" 5<<<"$folders_name")"
_clear_line 1
for _ in 1 2;do _clear_line 1;done
[[ -z ${files[*]:-${folders[*]}} ]]&&_print_center "justify" "$name" " | Empty Folder" "="&&_newline "\n"&&return 0
[[ -n ${files[*]} ]]&&num_of_files="${#files[@]}"
[[ -n ${folders[*]} ]]&&num_of_folders="${#folders[@]}"
_print_center "justify" "$name" "${num_of_files:+ | $num_of_files files}${num_of_folders:+ | $num_of_folders sub folders}" "="&&_newline "\n\n"
if [[ -f $name ]];then
name="$name$RANDOM"
fi&&mkdir -p "$name"
cd "$name"||exit 1
if [[ -n $num_of_files ]];then
if [[ -n $parallel ]];then
NO_OF_PARALLEL_JOBS_FINAL="$((NO_OF_PARALLEL_JOBS>num_of_files?num_of_files:NO_OF_PARALLEL_JOBS))"
[[ -f "$TMPFILE"SUCCESS ]]&&rm "$TMPFILE"SUCCESS
[[ -f "$TMPFILE"ERROR ]]&&rm "$TMPFILE"ERROR
printf "%s\n" "$files_list"|xargs -n1 -P"$NO_OF_PARALLEL_JOBS_FINAL" -i bash -c '
                _download_file_main parse "{}" true
            ' 1>|"$TMPFILE"SUCCESS 2>|"$TMPFILE"ERROR&
pid="$!"
until [[ -f "$TMPFILE"SUCCESS || -f "$TMPFILE"ERROR ]];do sleep 0.5;done
_clear_line 1
until ! kill -0 "$pid" 2>|/dev/null 1>&2;do
success_status="$(_count <"$TMPFILE"SUCCESS)"
error_status="$(_count <"$TMPFILE"ERROR)"
sleep 1
if [[ $((success_status+error_status)) != "$TOTAL" ]];then
printf '%s\r' "$(_print_center "justify" "Status" ": ${success_status:-0} Downloaded | ${error_status:-0} Failed" "=")"
fi
TOTAL="$((success_status+error_status))"
done
_newline "\n"
success_status="$(_count <"$TMPFILE"SUCCESS)"
error_status="$(_count <"$TMPFILE"ERROR)"
_clear_line 1&&_newline "\n"
else
while read -r -u 4 line;do
_download_file_main parse "$line"
: "$((RETURN_STATUS<2?(success_status+=1):(error_status+=1)))"
if [[ -z $VERBOSE ]];then
for _ in 1 2 3 4;do _clear_line 1;done
fi
_print_center "justify" "Status" ": ${success_status:-0} Downloaded | ${error_status:-0} Failed" "="
done 4<<<"$files_list"
fi
fi
for _ in 1 2;do _clear_line 1;done
[[ $success_status -gt 0 ]]&&"${QUIET:-_print_center}" "justify" "Downloaded" ": $success_status" "="
[[ $error_status -gt 0 ]]&&"${QUIET:-_print_center}" "justify" "Failed" ": $error_status" "="
_newline "\n"
if [[ -z $SKIP_SUBDIRS && -n $num_of_folders ]];then
while read -r -u 4 line;do
(_download_folder "${line%%"|:_//_:|"*}" "${line##*"|:_//_:|"}" "${parallel:-}")
done 4<<<"$folders_list"
fi
return 0
}
_log_in_file(){
[[ -z $LOG_FILE_ID || -d $LOG_FILE_ID ]]&&return 0
{
printf "%s\n" "Name: $1"
printf "%s\n" "Size: $2"
printf "%s\n\n" "ID: $3"
} >>"$LOG_FILE_ID"
}
_api_request(){
curl -e "https://drive.google.com" --compressed $CURL_PROGRESS \
"$API_URL/drive/$API_VERSION/${1:?}&key=$API_KEY&supportsAllDrives=true&includeItemsFromAllDrives=true"||return 1
_clear_line 1 1>&2
}
_api_request_oauth(){
. "${TMPFILE}_ACCESS_TOKEN"
curl --compressed $CURL_PROGRESS \
-H "Authorization: Bearer $ACCESS_TOKEN" \
"$API_URL/drive/$API_VERSION/${1:?}&supportsAllDrives=true&includeItemsFromAllDrives=true"||return 1
_clear_line 1 1>&2
}
_check_id(){
[[ $# == 0 ]]&&printf "%s: Missing arguments\n" "${FUNCNAME[0]}"&&return 1
"$EXTRA_LOG" "justify" "Validating URL/ID.." "-"
declare id="$1" json&&unset NAME SIZE
if json="$("$API_REQUEST_FUNCTION" "files/$id?alt=json&fields=name,size,mimeType")";then
if ! _json_value code 1 1 <<<"$json" 2>|/dev/null 1>&2;then
NAME="$(_json_value name 1 1 <<<"$json"||:)"
mime="$(_json_value mimeType 1 1 <<<"$json"||:)"
_clear_line 1
if [[ $mime =~ folder ]];then
FOLDER_ID="$id"
_print_center "justify" "Folder Detected" "="&&_newline "\n"
else
SIZE="$(_json_value size 1 1 <<<"$json"||:)"
FILE_ID="$id"
_print_center "justify" "File Detected" "="&&_newline "\n"
fi
export NAME SIZE FILE_ID FOLDER_ID
else
_clear_line 1&&"${QUIET:-_print_center}" "justify" "Invalid URL/ID" "="&&_newline "\n"
return 1
fi
else
_clear_line 1
"${QUIET:-_print_center}" "justify" "Error: Cannot check URL/ID" "="
printf "%s\n" "$json"
return 1
fi
return 0
}
_extract_id(){
[[ $# == 0 ]]&&printf "%s: Missing arguments\n" "${FUNCNAME[0]}"&&return 1
declare LC_ALL=C ID="$1"
case "$ID" in
*'drive.google.com'*'id='*)ID="${ID##*id=}"&&ID="${ID%%\?*}"&&ID="${ID%%\&*}";;
*'drive.google.com'*'file/d/'*|'http'*'docs.google.com'*'/d/'*)ID="${ID##*\/d\/}"&&ID="${ID%%\/*}"&&ID="${ID%%\?*}"&&ID="${ID%%\&*}";;
*'drive.google.com'*'drive'*'folders'*)ID="${ID##*\/folders\/}"&&ID="${ID%%\?*}"&&ID="${ID%%\&*}"
esac
printf "%b" "${ID:+$ID\n}"
}
_get_access_token_and_update(){
RESPONSE="${1:-$(curl --compressed -s -X POST --data "client_id=$CLIENT_ID&client_secret=$CLIENT_SECRET&refresh_token=$REFRESH_TOKEN&grant_type=refresh_token" "$TOKEN_URL")}"||:
if ACCESS_TOKEN="$(_json_value access_token 1 1 <<<"$RESPONSE")";then
ACCESS_TOKEN_EXPIRY="$(($(printf '%(%s)T\n' "-1")+$(_json_value expires_in 1 1 <<<"$RESPONSE")-1))"
[[ -z $NO_UPDATE_TOKEN ]]&&{
_update_config ACCESS_TOKEN "$ACCESS_TOKEN" "$CONFIG"
_update_config ACCESS_TOKEN_EXPIRY "$ACCESS_TOKEN_EXPIRY" "$CONFIG"
}
else
"${QUIET:-_print_center}" "justify" "Error: Something went wrong" ", printing error." 1>&2
printf "%s\n" "$RESPONSE" 1>&2
return 1
fi
return 0
}
_usage(){
printf "%b" "
The script can be used to download file/directory from google drive.\n
Usage:\n ${0##*/} [options.. ] <file_[url|id]> or <folder[url|id]>\n
Options:\n
  -o | --oauth - Use this flag to trigger oauth authentication.\n
      Note: If both --oauth and --key flag is used, --oauth flag is preferred.\n
  -k | --key 'API KEY' ( optional arg ) - To download with api key. If api key is not specified, then the predefined api key will be used.\n
      To save your api key in config file, use 'gdl --key default=your api key'.
      API key will be saved in '$HOME/.gdl.conf' and will be used from now on.\n
      Note: If both --key and --key oauth is used, --oauth flag is preferred.\n
  -c | --config 'config file path' - Override default config file with custom config file. Default: $HOME/.gdl.conf\n
  -d | --directory 'foldername' - option to _download given input in custom directory.\n
  -s | --skip-subdirs - Skip downloading of sub folders present in case of folders.\n
  -p | --parallel 'no_of_files_to_parallely_upload' - Download multiple files in parallel.\n
  --speed 'speed' - Limit the download speed, supported formats: 1K, 1M and 1G.\n
  -R | --retry 'num of retries' - Retry the file upload if it fails, postive integer as argument. Currently only for file uploads.\n
  -l | --log 'file_to_save_info' - Save downloaded files info to the given filename.\n
  -q | --quiet - Supress the normal output, only show success/error upload messages for files, and one extra line at the beginning for folder showing no. of files and sub folders.\n
  -V | --verbose - Display detailed message (only for non-parallel uploads).\n
  --skip-internet-check - Do not check for internet connection, recommended to use in sync jobs.\n
  -u | --update - Update the installed script in your system.\n
  --info - Show detailed info, only if script is installed system wide.\n
  --uninstall - Uninstall script, remove related files.\n
  -D | --debug - Display script command trace.\n
  -h | --help - Display usage instructions.\n"
exit 0
}
_short_help(){
printf "No valid arguments provided, use -h/--help flag to see usage.\n"
exit 0
}
_auto_update(){
export REPO
(_REPO="$REPO"
command -v "$COMMAND_NAME" 1>/dev/null&&[[ -n ${_REPO:+${COMMAND_NAME:+${INSTALL_PATH:+${TYPE:+$TYPE_VALUE}}}} ]]&&[[ $((LAST_UPDATE_TIME+AUTO_UPDATE_INTERVAL)) -lt $(printf '%(%s)T\n' "-1") ]]&&_update 2>|/dev/null 1>&2) \
2>|/dev/null 1>&2&
return 0
}
_update(){
declare job="${1:-update}"
[[ $GLOBAL_INSTALL == true ]]&&! [[ $(id -u) == 0 ]]&&printf "%s\n" "Error: Need root access to update."&&return 0
[[ $job == uninstall ]]&&job_string="--uninstall"
_print_center "justify" "Fetching $job script.." "-"
declare repo="${REPO:-akianonymus/gdrive-downloader}" type_value="${TYPE_VALUE:-master}" cmd="${COMMAND_NAME:-gdl}" path="${INSTALL_PATH:-$HOME/.gdrive-downloader}"
if script="$(curl --compressed -Ls "https://github.com/$repo/raw/$type_value/install.sh")";then
_clear_line 1
printf "%s\n" "$script"|bash -s -- ${job_string:-} --skip-internet-check --cmd "$cmd" --path "$path"
else
_clear_line 1
"${QUIET:-_print_center}" "justify" "Error: Cannot download $job script." "=" 1>&2
exit 1
fi
exit "$?"
}
_info(){
if command -v "$COMMAND_NAME" 1>/dev/null&&[[ -n ${REPO:+${COMMAND_NAME:+${INSTALL_PATH:+${TYPE:+$TYPE_VALUE}}}} ]];then
for i in REPO INSTALL_PATH INSTALLATION TYPE TYPE_VALUE LATEST_INSTALLED_SHA;do
printf "%s\n" "$i=\"${!i}\""
done
else
printf "%s\n" "gdrive-downloader is not installed system wide."
fi
exit 0
}
_setup_arguments(){
[[ $# == 0 ]]&&printf "%s: Missing arguments\n" "${FUNCNAME[0]}"&&return 1
unset LOG_FILE_ID OAUTH_ENABLED API_KEY_DOWNLOAD CONFIG FOLDERNAME SKIP_SUBDIRS NO_OF_PARALLEL_JOBS PARALLEL_DOWNLOAD
unset DEBUG QUIET VERBOSE VERBOSE_PROGRESS SKIP_INTERNET_CHECK RETRY
unset ID_INPUT_ARRAY FINAL_INPUT_ARRAY
CURL_PROGRESS="-s" EXTRA_LOG=":"
CONFIG="$HOME/.gdl.conf"
API_KEY="AIzaSyD2dHsZJ9b4OXuy5B_owiL8W18NaNOM8tk"
API_URL="https://www.googleapis.com"
API_VERSION="v3"
SCOPE="$API_URL/auth/drive"
REDIRECT_URI="urn:ietf:wg:oauth:2.0:oob"
TOKEN_URL="https://accounts.google.com/o/oauth2/token"
_check_longoptions(){
[[ -z $2 ]]&&printf '%s: %s: option requires an argument\nTry '"%s -h/--help"' for more information.\n' "${0##*/}" "$1" "${0##*/}"&&exit 1
return 0
}
while [[ $# -gt 0 ]];do
case "$1" in
-h|--help)_usage;;
-D|--debug)DEBUG="true"&&export DEBUG;;
-u|--update)_check_debug&&_update;;
-U|--uninstall)_check_debug&&_update uninstall;;
--info)_info;;
-l|--log)_check_longoptions "$1" "$2"
LOG_FILE_ID="$2"&&shift
;;
-o|--oauth)OAUTH_ENABLED="true";;
-k|--key)API_KEY_DOWNLOAD="true"
_API_KEY="${2##default=}"
if [[ $_API_KEY =~ AIza[0-9A-Za-z_-]{35} ]];then
API_KEY="$_API_KEY"&&shift
[[ -z ${2##default=*} ]]&&UPDATE_DEFAULT_API_KEY="_update_config"
fi
;;
-c|--config)_check_longoptions "$1" "$2"
CONFIG="$2"&&shift
;;
-d|--directory)_check_longoptions "$1" "$2"
FOLDERNAME="$2"&&shift
;;
-s|--skip-subdirs)SKIP_SUBDIRS="true"
;;
-p|--parallel)_check_longoptions "$1" "$2"
if [[ $2 -gt 0 ]];then
NO_OF_PARALLEL_JOBS="$2"
else
printf "\nError: -p/--parallel value ranges between 1 to 10.\n"
exit 1
fi
PARALLEL_DOWNLOAD="parallel"&&shift
;;
--speed)_check_longoptions "$1" "$2"
regex='^([0-9]+)([k,K]|[m,M]|[g,G])+$'
if [[ $2 =~ $regex ]];then
CURL_SPEED="--limit-rate $2"&&shift
else
printf "Error: Wrong speed limit format, supported formats: 1K , 1M and 1G\n" 1>&2
exit 1
fi
;;
-R|--retry)_check_longoptions "$1" "$2"
if [[ $2 -gt 0 ]];then
RETRY="$2"&&shift
else
printf "Error: -R/--retry only takes positive integers as arguments, min = 1, max = infinity.\n"
exit 1
fi
;;
-q|--quiet)QUIET="_print_center_quiet";;
-V|--verbose)VERBOSE="true"
;;
--skip-internet-check)SKIP_INTERNET_CHECK=":"
;;
''|*)[[ -n $1 ]]&&{
if [[ $1 == -* ]];then
printf '%s: %s: Unknown option\nTry '"%s -h/--help"' for more information.\n' "${0##*/}" "$1" "${0##*/}"&&exit 1
else
ID_INPUT_ARRAY+=("$(_extract_id "$1")")
fi
}
esac
shift
done
[[ -z ${ID_INPUT_ARRAY[*]} ]]&&_short_help
[[ -n $OAUTH_ENABLED ]]&&unset API_KEY_DOWNLOAD
_check_debug
return 0
}
_check_credentials(){
NO_UPDATE_TOKEN=""
[[ -r $CONFIG ]]&&. "$CONFIG"
if [[ -n $OAUTH_ENABLED ]];then
! [[ -t 1 ]]&&[[ -z ${CLIENT_ID:+${CLIENT_SECRET:+$REFRESH_TOKEN}} ]]&&{
printf "%s\n" "Error: Script is not running in a terminal, cannot ask for credentials."
printf "%s\n" "Add in config manually if terminal is not accessible. CLIENT_ID, CLIENT_SECRET and REFRESH_TOKEN is required."&&return 1
}
until [[ -n $CLIENT_ID && -n $CLIENT_ID_VALID ]];do
[[ -n $CLIENT_ID ]]&&{
if [[ $CLIENT_ID =~ [0-9]+-[0-9A-Za-z_]{32}\.apps\.googleusercontent\.com ]];then
[[ -n $client_id ]]&&_update_config CLIENT_ID "$CLIENT_ID" "$CONFIG"
CLIENT_ID_VALID="true"&&continue
else
{ [[ -n $client_id ]]&&message="- Try again";}||message="in config ( $CONFIG )"
"${QUIET:-_print_center}" "normal" " Invalid Client ID $message " "-"&&unset CLIENT_ID client_id
fi
}
[[ -z $client_id ]]&&printf "\n"&&"${QUIET:-_print_center}" "normal" " Enter Client ID " "-"
[[ -n $client_id ]]&&_clear_line 1
printf -- "-> "
read -r CLIENT_ID&&client_id=1
done
until [[ -n $CLIENT_SECRET && -n $CLIENT_SECRET_VALID ]];do
[[ -n $CLIENT_SECRET ]]&&{
if [[ $CLIENT_SECRET =~ [0-9A-Za-z_]{20,} ]];then
[[ -n $client_secret ]]&&_update_config CLIENT_SECRET "$CLIENT_SECRET" "$CONFIG"
CLIENT_SECRET_VALID="true"&&continue
else
{ [[ -n $client_secret ]]&&message="- Try again";}||message="in config ( $CONFIG )"
"${QUIET:-_print_center}" "normal" " Invalid Client Secret $message " "-"&&unset CLIENT_SECRET client_secret
fi
}
[[ -z $client_secret ]]&&printf "\n"&&"${QUIET:-_print_center}" "normal" " Enter Client Secret " "-"
[[ -n $client_secret ]]&&_clear_line 1
printf -- "-> "
read -r CLIENT_SECRET&&client_secret=1
done
[[ -n $REFRESH_TOKEN ]]&&{
! [[ $REFRESH_TOKEN =~ 1//[0-9][0-9][0-9A-Za-z_]{26}-[0-9A-Za-z_]{50,} ]]&&"${QUIET:-_print_center}" "normal" " Error: Invalid Refresh token in config file, follow below steps.. " "-"&&unset REFRESH_TOKEN
}
[[ -z $REFRESH_TOKEN ]]&&{
printf "\n"&&"${QUIET:-_print_center}" "normal" "If you have a refresh token generated, then type the token, else leave blank and press return key.." " "
printf "\n"&&"${QUIET:-_print_center}" "normal" " Refresh Token " "-"&&printf -- "-> "
read -r REFRESH_TOKEN
if [[ -n $REFRESH_TOKEN ]];then
"${QUIET:-_print_center}" "normal" " Checking refresh token.. " "-"
if [[ $REFRESH_TOKEN =~ 1//[0-9][0-9][0-9A-Za-z_]{26}-[0-9A-Za-z_]{50,} ]];then
{ _get_access_token_and_update&&_update_config REFRESH_TOKEN "$REFRESH_TOKEN" "$CONFIG";}||check_error=true
else
check_error=true
fi
[[ -n $check_error ]]&&"${QUIET:-_print_center}" "normal" " Error: Invalid Refresh token given, follow below steps to generate.. " "-"&&unset REFRESH_TOKEN
else
"${QUIET:-_print_center}" "normal" " No Refresh token given, follow below steps to generate.. " "-"
fi
[[ -z $REFRESH_TOKEN ]]&&{
printf "\n"&&"${QUIET:-_print_center}" "normal" "Visit the below URL, tap on allow and then enter the code obtained" " "
URL="https://accounts.google.com/o/oauth2/auth?client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URI&scope=$SCOPE&response_type=code&prompt=consent"
printf "\n%s\n" "$URL"
until [[ -n $CODE && -n $CODE_VALID ]];do
[[ -n $CODE ]]&&{
if [[ $CODE =~ [0-9]/[0-9A-Za-z_-]{50,} ]];then
CODE_VALID="true"&&continue
else
"${QUIET:-_print_center}" "normal" " Invalid CODE given, try again.. " "-"&&unset CODE code
fi
}
{ [[ -z $code ]]&&printf "\n"&&"${QUIET:-_print_center}" "normal" " Enter the authorization code " "-";}||_clear_line 1
printf -- "-> "
read -r CODE&&code=1
done
RESPONSE="$(curl --compressed "$CURL_PROGRESS" -X POST \
--data "code=$CODE&client_id=$CLIENT_ID&client_secret=$CLIENT_SECRET&redirect_uri=$REDIRECT_URI&grant_type=authorization_code" "$TOKEN_URL")"||:
_clear_line 1 1>&2
REFRESH_TOKEN="$(_json_value refresh_token 1 1 <<<"$RESPONSE"||:)"
{ _get_access_token_and_update "$RESPONSE"&&_update_config REFRESH_TOKEN "$REFRESH_TOKEN" "$CONFIG";}||return 1
}
printf "\n"
}
[[ -z $ACCESS_TOKEN || ! $ACCESS_TOKEN =~ ya29\.[0-9A-Za-z_-]+ || ${ACCESS_TOKEN_EXPIRY:-0} -lt "$(printf '%(%s)T\n' "-1")" ]]&&{ _get_access_token_and_update||return 1;}
{
while :;do
printf "%s\n" "export ACCESS_TOKEN=\"$ACCESS_TOKEN\" ACCESS_TOKEN_EXPIRY=\"$ACCESS_TOKEN_EXPIRY\"" >|"${TMPFILE}_ACCESS_TOKEN"
CURRENT_TIME="$(printf '%(%s)T\n' "-1")"
REMAINING_TOKEN_TIME="$((ACCESS_TOKEN_EXPIRY-CURRENT_TIME))"
if [[ $REMAINING_TOKEN_TIME -le 300 ]];then
{ export NO_UPDATE_TOKEN=true&&_timeout 30 _get_access_token_and_update;}||:
else
TOKEN_PROCESS_TIME_TO_SLEEP="$(if [[ $REMAINING_TOKEN_TIME -le 301 ]];then
printf "0\n"
else
printf "%s\n" "$((REMAINING_TOKEN_TIME-300))"
fi)"
sleep "$TOKEN_PROCESS_TIME_TO_SLEEP"
fi
sleep 1
done
}&
ACCESS_TOKEN_SERVICE_PID="$!"
elif [[ -n $API_KEY_DOWNLOAD ]];then
"${UPDATE_DEFAULT_API_KEY:-:}" API_KEY "$API_KEY" "$CONFIG"
fi
return 0
}
_process_arguments(){
export DEBUG LOG_FILE_ID VERBOSE API_KEY API_URL API_VERSION \
FOLDERNAME SKIP_SUBDIRS NO_OF_PARALLEL_JOBS PARALLEL_DOWNLOAD SKIP_INTERNET_CHECK \
COLUMNS CURL_SPEED TMPFILE CURL_PROGRESS EXTRA_LOG RETRY QUIET \
OAUTH_ENABLED API_KEY_DOWNLOAD
export -f _bytes_to_human _count _api_request _api_request_oauth _json_value _print_center _print_center _newline _clear_line \
_download_file _download_file_main _download_folder _log_in_file
${FOLDERNAME:+mkdir -p $FOLDERNAME}
cd "${FOLDERNAME:-.}" 2>|/dev/null 1>&2||exit 1
unset Aseen&&declare -A Aseen
for id in "${ID_INPUT_ARRAY[@]}";do
{ [[ ${Aseen[$id]} ]]&&continue;}||Aseen[$id]=x
_check_id "$id"||continue
if [[ -n $FOLDER_ID ]];then
_download_folder "$FOLDER_ID" "$NAME" "${PARALLEL_DOWNLOAD:-}"
else
_download_file_main noparse "$FILE_ID" "$NAME" "$SIZE"
fi
done
return 0
}
main(){
[[ $# == 0 ]]&&_short_help
[[ -z $SELF_SOURCE ]]&&{
UTILS_FOLDER="${UTILS_FOLDER:-$PWD}"
{ . "$UTILS_FOLDER"/common-utils.bash&&. "$UTILS_FOLDER"/download-utils.bash&&. "$UTILS_FOLDER"/drive-utils.bash;}||{ printf "Error: Unable to source util files.\n"&&exit 1;}
}
_check_bash_version&&set -o errexit -o noclobber -o pipefail
TMPFILE="$(command -v mktemp 1>|/dev/null&&mktemp -u)"||TMPFILE="$(pwd)/$(printf '%(%s)T\n' "-1").tmpfile"
export TMPFILE
_setup_arguments "$@"
"${SKIP_INTERNET_CHECK:-_check_internet}"
_cleanup(){
{
[[ -n $OAUTH_ENABLED ]]&&{
[[ $(. "${TMPFILE}_ACCESS_TOKEN"&&printf "%s\n" "$ACCESS_TOKEN") == "$ACCESS_TOKEN" ]]||{
_update_config ACCESS_TOKEN "$ACCESS_TOKEN" "$CONFIG"
_update_config ACCESS_TOKEN_EXPIRY "$ACCESS_TOKEN_EXPIRY" "$CONFIG"
}
token_service_pids="$(ps --ppid="$ACCESS_TOKEN_SERVICE_PID" -o pid=)"
kill "$ACCESS_TOKEN_SERVICE_PID"
for pid in $token_service_pids;do
kill "$pid"
done
}
rm -f "${TMPFILE:?}"*
export abnormal_exit&&if [[ -n $abnormal_exit ]];then
printf "\n\n%s\n" "Script exited manually."
kill -- -$$&
else
_auto_update
fi
} 2>|/dev/null||:
return 0
}
trap 'abnormal_exit="1"; exit' INT TERM
trap '_cleanup' EXIT
if [[ -n $OAUTH_ENABLED ]];then
"$EXTRA_LOG" "justify" "Checking credentials.." "-"
{ _check_credentials&&for _ in 1 2;do _clear_line 1;done;}||{ "${QUIET:-_print_center}" "normal" "[ Error: Credentials checking failed ]" "="&&exit 1;}
_print_center "justify" "Required credentials available." "="
export API_REQUEST_FUNCTION="_api_request_oauth"
else
export API_REQUEST_FUNCTION="_api_request"
fi
START="$(printf '%(%s)T\n' "-1")"
_process_arguments
END="$(printf '%(%s)T\n' "-1")"
DIFF="$((END-START))"
"${QUIET:-_print_center}" "normal" " Time Elapsed: ""$((DIFF/60))"" minute(s) and ""$((DIFF%60))"" seconds. " "="
}
{ [[ -z $SOURCED_GDL ]]&&main "$@";}||:
